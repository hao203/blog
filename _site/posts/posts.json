[
  {
    "path": "posts/2022-05-22-tongueeating/",
    "title": "食物/药物与舌象数据库-tongue_eating",
    "description": "一个用于展示食物/药物对舌象影响的数据库.",
    "author": [
      {
        "name": "Hao Liang",
        "url": "https://github.com/hao203/blog"
      }
    ],
    "date": "2022-05-22",
    "categories": [],
    "contents": "\r\n测试中 详见 https://medai.vip/tongue\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-08-25T11:09:52+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-14-Apriori/",
    "title": "关联规则在名医经验数据挖掘中的应用",
    "description": "智能医学社公开课",
    "author": [
      {
        "name": "Hao Liang",
        "url": "https://github.com/hao203/blog"
      }
    ],
    "date": "2021-03-14",
    "categories": [
      "Digital Chinese medicine",
      "R tips"
    ],
    "contents": "\r\n\r\nContents\r\n关联规则理论\r\n什么是关联分析\r\n啤酒与尿布\r\n关联分析及关联规则定义\r\n应用场景\r\nIn medicine\r\n\r\n一些概念\r\n事物库（数据集）dataset\r\n项集-Itemset\r\n支持度计数-Support count (\\(\\sigma\\))\r\n支持度-Support(s)\r\n频繁项集 - Frequent Itemset\r\n置信度-Confidence(c)\r\n例子\r\n\r\nSummary\r\n这两个度的意义在哪里？\r\nLift 提升度\r\n\r\n\r\nApriori Algorithm\r\nAssociation rule mining: Two-step process\r\nStep 1 第一步的困局\r\n我们今天的主角———Apriori算法\r\n原则\r\n流程\r\n\r\nStep 2 生成关联规则\r\n参考文献\r\n\r\nCode\r\nread data and library the packages\r\n寻找频繁项集（Find all frequent itemsets）\r\n按要求排序\r\n按置信度\r\n\r\n可视化\r\n散点图\r\n关系图\r\n\r\n\r\n\r\n源码地址：https://github.com/hao203/blog/tree/master/_posts/2021-03-14-Apriori\r\n关联规则理论\r\n什么是关联分析\r\n啤酒与尿布\r\n在美国有婴儿的家庭中，通常是母亲在家中照看婴儿，父亲去超市为婴儿购买尿布。当丈夫在为孩子购买尿布的同时，也通常购买自己爱喝的啤酒。因此，沃尔玛超市发现这一规律后，将啤酒与尿布放在相同的区域，使得父亲可以同时买到这两件商品，从而提高啤酒与尿布的销售量。\r\n关联分析又被称为购物篮分析（market basket analysis）\r\n关联性不代表因果关系，e.g.尿布\\(\\rightarrow\\)啤酒\r\n关联分析及关联规则定义\r\n\r\n实际上，超市这种销售的行为不是偶然的，而是长期从顾客的大量订单中分析,从而得出的结论。关联分析，就是从大规模数据中，发现对象之间隐含关系与规律的过程，也称为关联规则分析。例如，{啤酒\\(\\rightarrow\\)尿布}就是一个关联规则。\r\nAssociation rules analysis is a technique to uncover how items are associated to each other.\r\n应用场景\r\n超市购物分析\r\n图书购买分析\r\n服装搭配分析\r\n交通事故分析\r\n医学数据分析\r\n社交关系分析\r\nIn medicine\r\nRelationships between symptoms and illnesses; diagnosis and patient characteristics and treatments (to be used in medical DSS); and genes and their functions (to be used in genomics projects)…\r\n一些概念\r\n事物库（数据集）dataset\r\nTID\r\nItems\r\n1\r\nBread, Milk\r\n2\r\nBread, Diaper, Beer, Eggs\r\n3\r\nMilk, Diaper, Beer, Coke\r\n4\r\nBread, Milk, Diaper, Beer\r\n5\r\nBread, Milk, Diaper, Coke\r\n如同上表所示的二维数据集就是一个购物篮事务库。该事物库记录的是顾客购买商品的行为。这里的TID表示一次购买行为的编号，items表示顾客购买了哪些商品。\r\n事务库中的每一条记录被称为一笔事务。在上表的购物篮事务中，每一笔事务都表示一次购物行为。\r\n项集-Itemset\r\n苹果，香蕉等每一个水果对象，都是一个项。\r\n而一个或更多水果(项)构成的集合,就是项集。例如，{葡萄}, {香蕉，梨}都是项集。\r\nItemset\r\nA collection of one or more items\r\nExample: {Milk, Bread, Diaper}\r\n\r\nk-itemset\r\nAn itemset that contains k items\r\n\r\n支持度计数-Support count (\\(\\sigma\\))\r\n项集在事务中出现的次数。例如，｛Bread，Milk｝这个项集在事务库中一共出现了3次，那么它的支持度计数就是3。\r\n支持度-Support(s)\r\n包含项集的事务在所有事务中所占的比例：，这里N是所有事务的数量。上面的例子中我们得到了{Bread，Milk}这个项集的支持度计数是3，事物库中一共有5条事务，那么{Bread，Milk}这个项集的支持度就是3/5 (60%)。\r\nFraction of transactions that contain an itemset\r\nE.g. s({Milk, Bread, Diaper}) = 2/5\r\n\r\nX \\(\\rightarrow\\) Y : s = \\(\\frac{\\sigma (X)}{N}\\) = \\(\\frac{count(X)}{N}\\)\r\n\r\n频繁项集 - Frequent Itemset\r\n如果我们对项目集的支持度设定一个最小阈值，那么所有支持度大于这个阈值的项集就是频繁项集。\r\nAn itemset whose support is greater than or equal to a min(s) threshold\r\nThe set of frequent k-itemsets is commonly denoted by \\(L_K\\).\r\n置信度-Confidence(c)\r\n关联规则的置信度定义为：这个定义确定的是Y在包含X的事务中出现的频繁程度。还是看｛Bread，Milk｝→{Diaper}这个例子，包含｛Bread，Milk｝项的事务出现了2次，包含｛Bread，Milk，Diaper}的事务也出现了2次，那么这个规则的置信度就是1。\r\n\r\nX \\(\\rightarrow\\) Y : c = P(Y|X) = \\(\\frac{s(X,Y)}{s(X)}\\) = \\(\\frac{count(X,Y)}{count(X)}\\)\r\n\r\n例子\r\nExample of Rules:\r\n{Milk,Diaper}\\(\\rightarrow\\){Beer} (s=0.4, c=0.67)\r\n{Milk,Beer} \\(\\rightarrow\\) {Diaper} (s=0.4, c=1.0)\r\n{Diaper,Beer}\\(\\rightarrow\\){Milk} (s=0.4, c=0.67)\r\n{Beer}\\(\\rightarrow\\){Milk,Diaper} (s=0.4, c=0.67)\r\n{Diaper} \\(\\rightarrow\\) {Milk,Beer} (s=0.4, c=0.5)\r\n{Milk}\\(\\rightarrow\\){Diaper,Beer} (s=0.4, c=0.5)\r\nSummary\r\nAre all association rules interesting and useful?\r\nA Generic Rule: X \\(\\rightarrow\\) Y [S%, C%]\r\nX, Y: products and/or services\r\nX: Left-hand-side (LHS)\r\nY: Right-hand-side (RHS)\r\nS: Support: how often X and Y go together\r\nC: Confidence: how often Y go together with the X\r\n这两个度的意义在哪里？\r\n对于关联规则定义这两个度量很有意义的。首先，通过对规则支持度（s）的限定滤去没有意义的规则。我们从商家的角度出发，数据挖掘意义是通过挖掘做出相应的战略决策产生价值。如果一个规则支持度很低，说明顾客同时购买这些商品的次数很少，商家针对这个规则做决策几乎没有意义。其次，置信度（c）越大说明这个规则越可靠。\r\nAssociation rules are considered interesting if they satisfy both\r\na minimum support threshold and\r\na minimum confidence threshold.\r\nLift 提升度\r\n\\(Lift = \\frac{Confidence}{Expected\\ Confidence} = \\frac{P\\left(X \\cap Y\\right)}{P\\left(X\\right).P\\left(Y\\right)} = \\frac{c\\left(X \\rightarrow Y\\right)}{s\\left(Y\\right)} = \\frac{P(Y|X)}{P(Y)}\\)\r\n如果该值等于 1 ,说明两个条件没有任何关联。如果小于 1 ,说明 X 与 Y是负相关的关系，意味着一个出现可能导致另外一个不出现。大于 1 才表示具有正相关的关系。一般在数据挖掘中当提升度大于3 时,我们才承认挖掘出的关联规则是有价值的。\r\n他可以用来评估一个出现提升另外一个出现的程度。\r\n提升度是一种比较简单的判断手法，实际中受零事务（也即不包含 X 也不包含 Y 的事务）的影响比较大。所以如果数据中含有的零事务数量较大，该度量则不合适使用。\r\nApriori Algorithm\r\nAssociation rule mining: Two-step process\r\nFind all frequent itemsets\r\nBy definition, each of these itemsets will occur at least as frequently as a predetermined minimum support count, min_sup.\r\nGenerate strong association rules from the frequent itemsets\r\nBy definition, these rules must satisfy minimum support and minimum confidence.\r\nStep 1 第一步的困局\r\nA frequent itemset is an itemset whose support is ≥ minsup.\r\n一个看似简单的问题，实质要耗费巨大的计算量。\r\nFrequent itemset generation is still computationally expensive\r\nABCD,\\(2^4 - 1\\)Given d items, there are \\(2^d\\) possible candidate itemsets\r\n如果有d件商品，那么有\\(2^d - 1\\)种排列组合。\r\n对象之间任意组合构成的项集,数可能非常大。例如，在图中, 4个不同的对象(项)，就可以构成15种组合。而耐于含有N个对象 的数据集，若item种类稍大最终筛选的itemset就是天文数字，指数增长。所以我们迫切需要一种算法，能减少计算量。\r\n我们今天的主角———Apriori算法\r\n原则\r\n\r\nAll subsets of a frequent itemset must be frequent(Apriori propertry).\r\nIf an itemset is infrequent, all its supersets will be infrequent.\r\n\r\n频繁项集的所有子集都必是频繁的（Apriori属性）。\r\n如果一个项集是不频繁的，那么它的所有超集都是不频繁的。\r\nprincipleApriori算法会从k = 1开始,使用两个k项集进行组合,从而产生k + 1项集。结给之前介绍的算法原理，我们可知，频繁k + 1项集是由两个k项集组合而成，而耐于频繁k + 1项集来说，所有的k项集子集必然都是频繁项集，这就意味着,频繁k +1项集只可能从两个频繁项集组合产生,因此，当我们在组合的过程中，一旦发现某个k项集不是频繁项集(支持度小于指定的阈值)，就可以将其移除，无需再参与后续生成k + 1项集的组合。这样一来,就可以大大减少计算量。\r\n流程\r\nApriori算法流程如下:\r\n扫描数据集，从数据集中生成候选k项集\\(C_K\\)(k从1开始)\r\n计算\\(C_K\\)中,每个项集的支接，删除低于阈值的项集，构成频繁项集\\(L_K\\)。\r\n将频繁项集\\(L_K\\)中的元素进行组合,生成候选k + 1项集\\(C_{K+1}\\)\r\n重复步骤2,3,倒满足以下两个条件之-时,算法结束。\r\n频繁k项集无法组合生成候选k + 1项集。\r\n所有候选k项集支度都低于指定的阈值(最忮持渡)，无法生成频繁k项集。\r\n\r\nApriori stepsStep 2 生成关联规则\r\n当产生频繁项集后，成关联规则会相对简单。我们只需要将每个频繁项集拆分成两个非空子集，然后使用这两个子集，就可以构成关联规则。当然，-个频繁项集拆分两个非空子集可能有很多种方式，我们要考海种不同的可能。例如,频繁项集{1, 2, 3}可以拆分为:\r\n{1 -> 2,3}\r\n{2-> 1,3}\r\n{3-> 1, 2}\r\n{1,2-> 3}\r\n{1,3-> 2}\r\n{2,3-> 1}\r\n然后,我们针对每一个关联规则， 分别计算其置信度,仅保留符合最小置信度的关联规则。\r\n参考文献\r\nhttps://www.youtube.com/watch?v=0CB0Upqeh-o\r\nhttps://www.bilibili.com/video/BV1Kt4y1X7dZ\r\nhttps://rpubs.com/Argaadya/network-analysis-for-association-rules\r\nhttps://medium.com/@yolandawiyono98/market-basket-analysis-with-r-8001417a8e29\r\nCode\r\nread data and library the packages\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(arules)\r\nlibrary(arulesViz)\r\nlibrary(kableExtra)\r\nlibrary(rmarkdown)\r\nherbs <- read_csv('test.csv')\r\nherbs[] <- lapply(herbs, as.logical)\r\nherbs <- as(herbs,\"transactions\")\r\n\r\n\r\n\r\n寻找频繁项集（Find all frequent itemsets）\r\n\r\n\r\nrules <- apriori (herbs,  parameter = list(maxlen=3, supp =0.1, conf = 0.5))\r\nrules_df <- inspect(rules)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nsummary(rules)\r\n\r\n\r\nset of 109 rules\r\n\r\nrule length distribution (lhs + rhs):sizes\r\n 1  2  3 \r\n 1 49 59 \r\n\r\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n  1.000   2.000   3.000   2.532   3.000   3.000 \r\n\r\nsummary of quality measures:\r\n    support         confidence        coverage           lift       \r\n Min.   :0.1111   Min.   :0.5000   Min.   :0.1111   Min.   :0.8182  \r\n 1st Qu.:0.1111   1st Qu.:0.6667   1st Qu.:0.1296   1st Qu.:1.2273  \r\n Median :0.1296   Median :0.8571   Median :0.1481   Median :1.2462  \r\n Mean   :0.1578   Mean   :0.8070   Mean   :0.2078   Mean   :1.7403  \r\n 3rd Qu.:0.1481   3rd Qu.:1.0000   3rd Qu.:0.2037   3rd Qu.:1.7802  \r\n Max.   :0.8148   Max.   :1.0000   Max.   :1.0000   Max.   :5.9062  \r\n     count      \r\n Min.   :12.00  \r\n 1st Qu.:12.00  \r\n Median :14.00  \r\n Mean   :17.05  \r\n 3rd Qu.:16.00  \r\n Max.   :88.00  \r\n\r\nmining info:\r\n  data ntransactions support confidence\r\n herbs           108     0.1        0.5\r\n\r\n按要求排序\r\n###　按置支持度\r\n\r\n\r\nrules_s <- sort(rules, by=\"supp\", decreasing=TRUE) %>% \r\n inspect() \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n按置信度\r\n\r\n\r\nrules_c <- sort(rules, by=\"conf\", decreasing=TRUE)  %>% \r\n inspect()  \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n可视化\r\n散点图\r\n\r\n\r\nplot(rules)\r\n\r\n\r\n\r\nplot(rules, method = \"grouped\")\r\n\r\n\r\n\r\n\r\n关系图\r\n\r\n\r\nrules_c <- sort(rules, by=\"conf\", decreasing=TRUE) %>% \r\nhead(.,10) %>% \r\nplot(.,method=\"graph\")\r\n\r\n\r\n\r\nrules_s <- sort(rules, by=\"supp\", decreasing=TRUE) %>% \r\nhead(.,10) %>% \r\nplot(.,method=\"graph\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-14-Apriori/Apriori_files/figure-html5/unnamed-chunk-9-1.png",
    "last_modified": "2021-03-23T16:11:10+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-21-rmarkdown-tutorial/",
    "title": "Rmarkdown tutorial",
    "description": "A short description of the rmarkdwon tutorial.",
    "author": [
      {
        "name": "Hao Liang",
        "url": "https://coogle.ink"
      }
    ],
    "date": "2021-02-21",
    "categories": [
      "R markdown"
    ],
    "contents": "\n\nContents\nRmarkdown学术写作\n介绍\n适用人群\n课程大纲\n第一章 准备工作与理论\n第二章 基础操作与参数讲解\n第三章 实战学术写作\n\n关于作者\n\n\nRmarkdown学术写作\n介绍\nRmarkdown学术写作课程（医咖会）\n适用人群\n科研工作者、研究生、数据科学从业者等\n课程大纲\n第一章 准备工作与理论\nRmarkdown是什么（生态、作者、历史），可以做什么\n写论文\n写书\n写毕业论文\n写学术墙报\n写简历\n…\nRmarkdown写作的优势（相较于word、jupyter notebook）\nall in one (即将写作和统计分析、作图融合在一起，一个程序解决所有问题)\n兼容markdown语法、可以运行R以外的代码（python、javascript等）\n可以将文档转化成各种常见格式，便于发布和整理\n可以和git融合，方便版本控制，天生开源特性\n丰富的模板和自动化操作\nRstudio的安装、设置和包管理\nRstudio的安装及注意事项\nRstudio的设置\n包管理（内置方法、devtools、remotes、pacman）\nRmarkdown需要安装的包\ntinytex\nrticles\ntidyverse\nbookdown\nRmarkdown的结构及工作原理\nRmd文件结构（yaml、text（markdown、latex）、chunk option、code chunk）\n第二章 基础操作与参数讲解\nyaml头部及参数\nyaml this包快速设置\nyaml语法注意事项\n常见参数设置title|author|output|toc|template|reference等\nmarkdown语法速成（10分钟）\nchunk（代码块）\n插入代码块（R和python演示）\nchunk option\n表格\n表格使用的包（flextable、kable）\n和我一起Table one\n图片\nchunk文档内生成图片\n外部图片\n文档拆分与合并\n引用\ncsl及引文样式\n配合参考文献管理工具（jabref、endnote、zotero）\n参考文献引用（1.4版本说明）\n文档内部引用（引用图片、表格或某章节）\n一些格式操作\n分页\nheader latex设置和模板\n首行缩进\n输出操作\npdf\nword\nhtml\n第三章 实战学术写作\n实战\n写一个完整的manuscript\n关于rticles包\n写一个post（postdown包）\n写一本书，以R Markdown Cookbook这本开元书籍为例\n写一个学术简历（vitae包）\n结语\n我的一些理念\n对R的未来畅想\n致谢\n关于作者\n湖南中医药大学 梁昊 医学博士，讲师，主治医师\n\n\n\n",
    "preview": {},
    "last_modified": "2021-03-18T15:16:39+08:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Curriculum Vitae - Hao Liang (梁昊)",
    "description": "Welcome to our new blog, liang Blog. We hope you enjoy \nreading what we have to say!",
    "author": [
      {
        "name": "Hao Liang",
        "url": "https://medai.vip/"
      }
    ],
    "date": "2021-02-14",
    "categories": [],
    "contents": "\n这个是梁昊老师的个人博客，用于我自己教程发布及个人学术的一些介绍和展示\n\n\n\n",
    "preview": {},
    "last_modified": "2021-04-21T22:06:18+08:00",
    "input_file": {}
  }
]
